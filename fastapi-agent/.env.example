# LLM Configuration - Choose between "ollama" (self-hosted) or "litellm" (Hyland ML platform)
LLM_CHOICE=ollama

# Ollama Configuration (self-hosted)
OLLAMA_MODEL=gpt-oss:20b
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=300

# LiteLLM Configuration (Hyland ML platform)
LITELLM_MODEL=litellm_proxy/anthropic.claude-sonnet-4-20250514-v1:0
LITELLM_API_KEY=your-api-key-here
LITELLM_API_BASE=https://api.ai.dev.experience.hyland.com/litellm

# MCP Tools
MCP_SERVER_URL=http://localhost:8003/mcp
